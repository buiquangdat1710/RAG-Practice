import streamlit as st
from embeddings import Embeddings
from vector_db import VectorDatabase
from semantic_router.route import Route
from semantic_router.router import SemanticRouter
from semantic_router.samples import productsSample, chitchatSample
from reflection import Reflection
import pandas as pd
import openai
import os
import numpy as np

# H√†m gh√©p th√¥ng tin s·∫£n ph·∫©m
def build_combine_row(row):
    combine = f"T√™n s·∫£n ph·∫©m: {row['title']}\n"
    combine += f"M√¥ t·∫£: {row['product_specs']}\n"
    combine += f"Gi√°: {row['current_price']}\n"
    combine += f"∆Øu ƒë√£i: {row['product_promotion']}\n"
    combine += f"M√†u s·∫Øc: {row['color_options']}\n"
    return combine

# Kh·ªüi t·∫°o session_state ƒë·ªÉ l∆∞u h·ªôi tho·∫°i
def init_session():
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": """B·∫°n l√† m·ªôt nh√¢n vi√™n t∆∞ v·∫•n b√°n h√†ng chuy√™n nghi·ªáp t·∫°i c·ª≠a h√†ng Quang ƒê·∫°t Phone. X∆∞ng em v√† x∆∞ng kh√°ch h√†ng l√† anh/ch·ªã. ƒê√¥i khi s·ª≠ d·ª•ng icon emoji trong c√¢u tr·∫£ l·ªùi. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa kh√°ch h√†ng m·ªôt c√°ch r√µ r√†ng, th√¢n thi·ªán v√† d·ª±a ho√†n to√†n v√†o c√°c th√¥ng tin s·∫£n ph·∫©m ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi.
Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin c√≥ trong d·ªØ li·ªáu. Kh√¥ng t·ª± t·∫°o ra th√¥ng tin n·∫øu kh√¥ng ƒë∆∞·ª£c cung c·∫•p.
N·∫øu kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi, h√£y l·ªãch s·ª± tr·∫£ l·ªùi r·∫±ng hi·ªán t·∫°i b·∫°n ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ t∆∞ v·∫•n ch√≠nh x√°c.
H√£y ∆∞u ti√™n ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu. N·∫øu kh√°ch h·ªèi g·ª£i √Ω s·∫£n ph·∫©m, h√£y li·ªát k√™ m·ªôt v√†i m·∫´u ph√π h·ª£p v√† l√Ω do t·∫°i sao n√™n ch·ªçn.
Lu√¥n gi·ªØ th√°i ƒë·ªô l·ªãch s·ª±, chuy√™n nghi·ªáp v√† h·ªó tr·ª£ h·∫øt m√¨nh."""}
        ]
    if "history" not in st.session_state:
        st.session_state.history = []

# H√†m load d·ªØ li·ªáu v√† setup
@st.cache_resource(show_spinner="üîÑ ƒêang load d·ªØ li·ªáu...")
def setup():
    df = pd.read_csv("hoanghamobile.csv")
    df['information'] = df.apply(build_combine_row, axis=1)

    vector_db = VectorDatabase(db_type="mongodb")
    embedding = Embeddings(model_name="text-embedding-3-small", type="openai")

    routes = [
        Route(name="products", samples=productsSample),
        Route(name="chitchat", samples=chitchatSample)
    ]
    router = SemanticRouter(embedding, routes)

    if vector_db.count_documents("products") == 0:
        for _, row in df.iterrows():
            embedding_vector = embedding.encode(row['information'])
            vector_db.insert_document(
                "products",
                {
                    "title": row['title'],
                    "embedding": embedding_vector,
                    "information": row['information']
                }
            )
    return embedding, vector_db, router

# H√†m x·ª≠ l√Ω truy v·∫•n ng∆∞·ªùi d√πng
def handle_query(query, embedding, vector_db, router):
    openai.api_key = os.getenv("OPENAI_API_KEY")
    reflection = Reflection(openai)

    rewritten_query = reflection.rewrite(st.session_state.messages, query)
    route_result = router.guide(rewritten_query)
    best_route = route_result[1]

    st.chat_message("assistant").markdown(f"**[ƒê·ªãnh tuy·∫øn]:** `{best_route}`")

    if best_route == "uncertain":
        return "ü§î Em ch∆∞a ch·∫Øc ch·∫Øn v·ªÅ c√¢u h·ªèi n√†y. Anh/ch·ªã c√≥ th·ªÉ n√≥i r√µ h∆°n ƒë∆∞·ª£c kh√¥ng?"

    elif best_route == "products":
        query_embedding = embedding.encode(rewritten_query)
        results = vector_db.query("products", query_embedding, limit=5)

        context = ""
        for r in results:
            context += f"{r['information']}\n"

        base_prompt = st.session_state.messages[0]["content"]
        st.session_state.messages[0]["content"] = base_prompt + f"\nD·ªØ li·ªáu s·∫£n ph·∫©m li√™n quan:\n{context}"
        st.session_state.messages.append({"role": "user", "content": rewritten_query})

    else:
        st.session_state.messages.append({"role": "user", "content": query})

    # G·ªçi OpenAI chat d·∫°ng stream
    response_stream = embedding.client.chat.completions.create(
        model="gpt-4o-mini",
        messages=st.session_state.messages,
        stream=True
    )

    assistant_reply = ""
    placeholder = st.empty()
    for chunk in response_stream:
        if chunk.choices and chunk.choices[0].delta.content:
            token = chunk.choices[0].delta.content
            assistant_reply += token
            placeholder.markdown(assistant_reply + "‚ñå")

    placeholder.markdown(assistant_reply)
    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
    return None

# ---------- Giao di·ªán Streamlit ----------
st.set_page_config(page_title="T∆∞ v·∫•n Quang ƒê·∫°t Phone", page_icon="üì±", layout="centered")
st.title("üìû Chatbot T∆∞ v·∫•n Quang ƒê·∫°t Phone")

init_session()
embedding, vector_db, router = setup()

for msg in st.session_state.messages[1:]:  # B·ªè system prompt
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("Anh/ch·ªã mu·ªën h·ªèi g√¨ v·ªÅ s·∫£n ph·∫©m?")
if user_input:
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    handle_query(user_input, embedding, vector_db, router)
