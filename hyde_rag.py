from embeddings import Embeddings
from vector_db import VectorDatabase
import pandas as pd
from semantic_router.route import Route
from semantic_router.router import SemanticRouter
from semantic_router.samples import productsSample
from semantic_router.samples import chitchatSample
from reflection import Reflection
import openai
import os
from rerank import Reranker


def build_combine_row(row):
    combine = f"TÃªn sáº£n pháº©m: {row['title']}\n"
    combine += f"MÃ´ táº£: {row['product_specs']}\n"
    combine += f"GiÃ¡: {row['current_price']}\n"
    combine += f"Æ¯u Ä‘Ã£i: {row['product_promotion']}\n"
    combine += f"MÃ u sáº¯c: {row['color_options']}\n"
    return combine

def main():
    df = pd.read_csv("hoanghamobile.csv")
    df['information'] = df.apply(build_combine_row, axis=1)

    vector_db = VectorDatabase(db_type="mongodb")
    embedding = Embeddings(model_name="text-embedding-3-large", type="openai")
    reranker = Reranker()
    routes = [
        Route(name="products", samples=productsSample),
        Route(name="chitchat", samples=chitchatSample)
    ]
    router = SemanticRouter(embedding, routes)
    if vector_db.count_documents("products") == 0:
        print("ğŸ”„ ChÆ°a cÃ³ dá»¯ liá»‡u trong DB, báº¯t Ä‘áº§u chÃ¨n dá»¯ liá»‡u...")
        for index, row in df.iterrows():
            title = row['title']
            doc = row['information']
            embedding_vector = embedding.encode(doc)
            vector_db.insert_document(
                collection_name="products",
                document={
                    "title": title,
                    "embedding": embedding_vector,
                    "information": doc
                }
            )
            print(f"Inserted document {index + 1}/{len(df)}: {title}")
        print("âœ… ÄÃ£ chÃ¨n xong toÃ n bá»™ dá»¯ liá»‡u.")
    else:
        print("âœ… Dá»¯ liá»‡u Ä‘Ã£ tá»“n táº¡i trong MongoDB, bá» qua bÆ°á»›c insert.")

    print("Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng. Báº¡n cÃ³ thá»ƒ há»i vá» sáº£n pháº©m. GÃµ 'quit' Ä‘á»ƒ thoÃ¡t.")
    
    # LÆ°u toÃ n bá»™ lá»‹ch sá»­ há»™i thoáº¡i
    messages = [
        {
            "role": "system",
            "content": """Báº¡n lÃ  má»™t nhÃ¢n viÃªn tÆ° váº¥n bÃ¡n hÃ ng chuyÃªn nghiá»‡p táº¡i cá»­a hÃ ng Quang Äáº¡t Phone. XÆ°ng em vÃ  xÆ°ng khÃ¡ch hÃ ng lÃ  anh/chá»‹. ÄÃ´i khi sá»­ dá»¥ng icon emoji trong cÃ¢u tráº£ lá»i. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a khÃ¡ch hÃ ng má»™t cÃ¡ch rÃµ rÃ ng, thÃ¢n thiá»‡n vÃ  dá»±a hoÃ n toÃ n vÃ o cÃ¡c thÃ´ng tin sáº£n pháº©m Ä‘Æ°á»£c cung cáº¥p bÃªn dÆ°á»›i.
Chá»‰ sá»­ dá»¥ng thÃ´ng tin cÃ³ trong dá»¯ liá»‡u. KhÃ´ng tá»± táº¡o ra thÃ´ng tin náº¿u khÃ´ng Ä‘Æ°á»£c cung cáº¥p.
Náº¿u khÃ´ng tÃ¬m tháº¥y cÃ¢u tráº£ lá»i, hÃ£y lá»‹ch sá»± tráº£ lá»i ráº±ng hiá»‡n táº¡i báº¡n chÆ°a cÃ³ Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tÆ° váº¥n chÃ­nh xÃ¡c.
HÃ£y Æ°u tiÃªn ngáº¯n gá»n, dá»… hiá»ƒu. Náº¿u khÃ¡ch há»i gá»£i Ã½ sáº£n pháº©m, hÃ£y liá»‡t kÃª má»™t vÃ i máº«u phÃ¹ há»£p vÃ  lÃ½ do táº¡i sao nÃªn chá»n.
LuÃ´n giá»¯ thÃ¡i Ä‘á»™ lá»‹ch sá»±, chuyÃªn nghiá»‡p vÃ  há»— trá»£ háº¿t mÃ¬nh."""
        }
    ]

    while True:
        query = input("ğŸ’¬ CÃ¢u há»i cá»§a báº¡n: ")
        if query.strip().lower() in ["quit", "exit"]:
            print("Táº¡m biá»‡t anh/chá»‹! Háº¹n gáº·p láº¡i ğŸ˜Š")
            break

        # PhÃ¢n loáº¡i báº±ng Semantic Router
        openai.api_key = os.getenv("OPENAI_API_KEY")
        # reflection = Reflection(openai)
        # rewritten_query = reflection.rewrite(messages, query)
        route_result = router.guide(query)
        best_route = route_result[1]
        print(route_result)
        print(f"[Semantic Router] â†’ PhÃ¢n loáº¡i: {best_route}")

        if best_route == "uncertain":
            # CÃ³ thá»ƒ há»i láº¡i user hoáº·c fallback sang chitchat
            print("ğŸ¤” Em khÃ´ng cháº¯c cháº¯n cÃ¢u há»i nÃ y. Anh/chá»‹ cÃ³ thá»ƒ nÃ³i rÃµ hÆ¡n Ä‘Æ°á»£c khÃ´ng?")
            continue

        elif best_route == "products":
            # RAG
            hyde_prompt = f"Viáº¿t má»™t Ä‘oáº¡n vÄƒn Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i sau má»™t cÃ¡ch chi tiáº¿t vÃ  tá»± nhiÃªn:\n{query}"
            hyde_response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": hyde_prompt}]
            )
            hyde_generated = hyde_response.choices[0].message.content.strip()
            print("\nğŸ§ª [HyDE] VÄƒn báº£n sinh ra:")
            print(hyde_generated)

            # Encode Ä‘oáº¡n vÄƒn giáº£ Ä‘á»‹nh thay vÃ¬ encode query gá»‘c
            query_embedding = embedding.encode(hyde_generated)

            # Truy váº¥n DB nhÆ° trÆ°á»›c
            results = vector_db.query("products", query_embedding, limit=7)
            cnt = 0
            print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
            for result in results:
                print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
                print(f"Title: {result['title']}")
                print(f"Information: {result['information']}")
                print("-" * 50)
                cnt += 1
    
            passages = [result["information"] for result in results]
            scores, ranked_passages = reranker(query, passages)

            # In káº¿t quáº£ sau reranking
            print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
            for i, (score, passage) in enumerate(zip(scores, ranked_passages)):
                print(f"\nğŸ“„ VÄƒn báº£n {i+1} | Score: {score:.4f}")
                print(passage)
                print("-" * 50)

            context = "\n".join(ranked_passages[:5])

            system_content = messages[0]["content"]  # Láº¥y prompt ban Ä‘áº§u
            new_system_content = system_content + f"\nDá»¯ liá»‡u sáº£n pháº©m liÃªn quan:\n{context}"
            messages[0]["content"] = new_system_content  # Gá»™p context vÃ o system Ä‘á»ƒ giá»¯ continuity

            messages.append({"role": "user", "content": query})
        else:
            messages.append({"role": "user", "content": query})

        response = embedding.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages
        )
        reply = response.choices[0].message.content.strip()
        print("ğŸ¤– Tráº£ lá»i:", reply)
        print("-" * 80)

        messages.append({"role": "assistant", "content": reply})


    
if __name__ == "__main__":
    main()
