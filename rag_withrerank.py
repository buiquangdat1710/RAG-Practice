from embeddings import Embeddings
from vector_db import VectorDatabase
import pandas as pd
from semantic_router.route import Route
from semantic_router.router import SemanticRouter
from semantic_router.samples import productsSample
from semantic_router.samples import chitchatSample
from reflection import Reflection
import openai
import os
from rerank import Reranker


def build_combine_row(row):
    combine = f"T√™n s·∫£n ph·∫©m: {row['title']}\n"
    combine += f"M√¥ t·∫£: {row['product_specs']}\n"
    combine += f"Gi√°: {row['current_price']}\n"
    combine += f"∆Øu ƒë√£i: {row['product_promotion']}\n"
    combine += f"M√†u s·∫Øc: {row['color_options']}\n"
    return combine

def main():
    df = pd.read_csv("hoanghamobile.csv")
    df['information'] = df.apply(build_combine_row, axis=1)

    vector_db = VectorDatabase(db_type="mongodb")
    embedding = Embeddings(model_name="text-embedding-3-large", type="openai")
    reranker = Reranker()
    routes = [
        Route(name="products", samples=productsSample),
        Route(name="chitchat", samples=chitchatSample)
    ]
    router = SemanticRouter(embedding, routes)
    if vector_db.count_documents("products") == 0:
        print("üîÑ Ch∆∞a c√≥ d·ªØ li·ªáu trong DB, b·∫Øt ƒë·∫ßu ch√®n d·ªØ li·ªáu...")
        for index, row in df.iterrows():
            title = row['title']
            doc = row['information']
            embedding_vector = embedding.encode(doc)
            vector_db.insert_document(
                collection_name="products",
                document={
                    "title": title,
                    "embedding": embedding_vector,
                    "information": doc
                }
            )
            print(f"Inserted document {index + 1}/{len(df)}: {title}")
        print("‚úÖ ƒê√£ ch√®n xong to√†n b·ªô d·ªØ li·ªáu.")
    else:
        print("‚úÖ D·ªØ li·ªáu ƒë√£ t·ªìn t·∫°i trong MongoDB, b·ªè qua b∆∞·ªõc insert.")

    print("H·ªá th·ªëng ƒë√£ s·∫µn s√†ng. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ s·∫£n ph·∫©m. G√µ 'quit' ƒë·ªÉ tho√°t.")
    
    # L∆∞u to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i
    messages = [
        {
            "role": "system",
            "content": """B·∫°n l√† m·ªôt nh√¢n vi√™n t∆∞ v·∫•n b√°n h√†ng chuy√™n nghi·ªáp t·∫°i c·ª≠a h√†ng Quang ƒê·∫°t Phone. X∆∞ng em v√† x∆∞ng kh√°ch h√†ng l√† anh/ch·ªã. ƒê√¥i khi s·ª≠ d·ª•ng icon emoji trong c√¢u tr·∫£ l·ªùi. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa kh√°ch h√†ng m·ªôt c√°ch r√µ r√†ng, th√¢n thi·ªán v√† d·ª±a ho√†n to√†n v√†o c√°c th√¥ng tin s·∫£n ph·∫©m ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi.
Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin c√≥ trong d·ªØ li·ªáu. Kh√¥ng t·ª± t·∫°o ra th√¥ng tin n·∫øu kh√¥ng ƒë∆∞·ª£c cung c·∫•p.
N·∫øu kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi, h√£y l·ªãch s·ª± tr·∫£ l·ªùi r·∫±ng hi·ªán t·∫°i b·∫°n ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ t∆∞ v·∫•n ch√≠nh x√°c.
H√£y ∆∞u ti√™n ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu. N·∫øu kh√°ch h·ªèi g·ª£i √Ω s·∫£n ph·∫©m, h√£y li·ªát k√™ m·ªôt v√†i m·∫´u ph√π h·ª£p v√† l√Ω do t·∫°i sao n√™n ch·ªçn.
Lu√¥n gi·ªØ th√°i ƒë·ªô l·ªãch s·ª±, chuy√™n nghi·ªáp v√† h·ªó tr·ª£ h·∫øt m√¨nh."""
        }
    ]

    while True:
        query = input("üí¨ C√¢u h·ªèi c·ªßa b·∫°n: ")
        if query.strip().lower() in ["quit", "exit"]:
            print("T·∫°m bi·ªát anh/ch·ªã! H·∫πn g·∫∑p l·∫°i üòä")
            break

        # Ph√¢n lo·∫°i b·∫±ng Semantic Router
        openai.api_key = os.getenv("OPENAI_API_KEY")
        reflection = Reflection(openai)
        rewritten_query = reflection.rewrite(messages, query)
        route_result = router.guide(rewritten_query)
        best_route = route_result[1]
        print(route_result)
        print(f"[Semantic Router] ‚Üí Ph√¢n lo·∫°i: {best_route}")

        if best_route == "uncertain":
            # C√≥ th·ªÉ h·ªèi l·∫°i user ho·∫∑c fallback sang chitchat
            print("ü§î Em kh√¥ng ch·∫Øc ch·∫Øn c√¢u h·ªèi n√†y. Anh/ch·ªã c√≥ th·ªÉ n√≥i r√µ h∆°n ƒë∆∞·ª£c kh√¥ng?")
            continue

        elif best_route == "products":
            # RAG
            query_embedding = embedding.encode(rewritten_query)
            results = vector_db.query("products", query_embedding, limit=7)
            cnt = 0
            print("üìÑ K·∫øt qu·∫£ t√¨m ki·∫øm tr∆∞·ªõc khi rerank:")
            for result in results:
                print(f"VƒÉn b·∫£n s·ªë {cnt + 1}:")
                print(f"Title: {result['title']}")
                print(f"Information: {result['information']}")
                print("-" * 50)
                cnt += 1
    
            passages = [result["information"] for result in results]
            scores, ranked_passages = reranker(rewritten_query, passages)

            # In k·∫øt qu·∫£ sau reranking
            print("\nüìä K·∫øt qu·∫£ sau khi rerank:")
            for i, (score, passage) in enumerate(zip(scores, ranked_passages)):
                print(f"\nüìÑ VƒÉn b·∫£n {i+1} | Score: {score:.4f}")
                print(passage)
                print("-" * 50)

            context = "\n".join(ranked_passages[:5])

            system_content = messages[0]["content"]  # L·∫•y prompt ban ƒë·∫ßu
            new_system_content = system_content + f"\nD·ªØ li·ªáu s·∫£n ph·∫©m li√™n quan:\n{context}"
            messages[0]["content"] = new_system_content  # G·ªôp context v√†o system ƒë·ªÉ gi·ªØ continuity

            messages.append({"role": "user", "content": rewritten_query})
        else:
            messages.append({"role": "user", "content": query})

        response = embedding.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages
        )
        reply = response.choices[0].message.content.strip()
        print("ü§ñ Tr·∫£ l·ªùi:", reply)
        print("-" * 80)

        messages.append({"role": "assistant", "content": reply})


    
if __name__ == "__main__":
    main()
