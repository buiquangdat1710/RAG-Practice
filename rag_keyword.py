from embeddings import Embeddings
from vector_db import VectorDatabase
import pandas as pd
from semantic_router.route import Route
from semantic_router.router import SemanticRouter
from semantic_router.samples import productsSample
from semantic_router.samples import chitchatSample
from reflection import Reflection
import openai
import os
from rerank import Reranker
from elasticsearch_db import ElasticSearchDB


def build_combine_row(row):
    combine = f"T√™n s·∫£n ph·∫©m: {row['title']}\n"
    combine += f"M√¥ t·∫£: {row['product_specs']}\n"
    combine += f"Gi√°: {row['current_price']}\n"
    combine += f"∆Øu ƒë√£i: {row['product_promotion']}\n"
    combine += f"M√†u s·∫Øc: {row['color_options']}\n"
    return combine

def main():
    df = pd.read_csv("hoanghamobile.csv")
    df['information'] = df.apply(build_combine_row, axis=1)

    vector_db = VectorDatabase(db_type="mongodb")
    embedding = Embeddings(model_name="text-embedding-3-small", type="openai")
    routes = [
        Route(name="products", samples=productsSample),
        Route(name="chitchat", samples=chitchatSample)
    ]
    router = SemanticRouter(embedding, routes)
    es_db = ElasticSearchDB()
    if es_db.count_documents() == 0:
        print("üîÑ Ch∆∞a c√≥ d·ªØ li·ªáu trong Elasticsearch, ƒëang ch√®n...")
        for index, row in df.iterrows():
            doc = {
                "title": row["title"],
                "information": row["information"]
            }
            es_db.insert_document(doc)
            print(f"Inserted document {index + 1}/{len(df)}: {row['title']}")
        print("‚úÖ ƒê√£ ch√®n xong d·ªØ li·ªáu.")
    else:
        print("‚úÖ D·ªØ li·ªáu ƒë√£ t·ªìn t·∫°i trong Elasticsearch, b·ªè qua insert.")

    print("H·ªá th·ªëng ƒë√£ s·∫µn s√†ng. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ s·∫£n ph·∫©m. G√µ 'quit' ƒë·ªÉ tho√°t.")
    
    # L∆∞u to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i
    messages = [
        {
            "role": "system",
            "content": """B·∫°n l√† m·ªôt nh√¢n vi√™n t∆∞ v·∫•n b√°n h√†ng chuy√™n nghi·ªáp t·∫°i c·ª≠a h√†ng Quang ƒê·∫°t Phone. X∆∞ng em v√† x∆∞ng kh√°ch h√†ng l√† anh/ch·ªã. ƒê√¥i khi s·ª≠ d·ª•ng icon emoji trong c√¢u tr·∫£ l·ªùi. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa kh√°ch h√†ng m·ªôt c√°ch r√µ r√†ng, th√¢n thi·ªán v√† d·ª±a ho√†n to√†n v√†o c√°c th√¥ng tin s·∫£n ph·∫©m ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi.
Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin c√≥ trong d·ªØ li·ªáu. Kh√¥ng t·ª± t·∫°o ra th√¥ng tin n·∫øu kh√¥ng ƒë∆∞·ª£c cung c·∫•p.
N·∫øu kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi, h√£y l·ªãch s·ª± tr·∫£ l·ªùi r·∫±ng hi·ªán t·∫°i b·∫°n ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ t∆∞ v·∫•n ch√≠nh x√°c.
H√£y ∆∞u ti√™n ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu. N·∫øu kh√°ch h·ªèi g·ª£i √Ω s·∫£n ph·∫©m, h√£y li·ªát k√™ m·ªôt v√†i m·∫´u ph√π h·ª£p v√† l√Ω do t·∫°i sao n√™n ch·ªçn.
Lu√¥n gi·ªØ th√°i ƒë·ªô l·ªãch s·ª±, chuy√™n nghi·ªáp v√† h·ªó tr·ª£ h·∫øt m√¨nh."""
        }
    ]

    while True:
        query = input("üí¨ C√¢u h·ªèi c·ªßa b·∫°n: ")
        if query.strip().lower() in ["quit", "exit"]:
            print("T·∫°m bi·ªát anh/ch·ªã! H·∫πn g·∫∑p l·∫°i üòä")
            break

        # Ph√¢n lo·∫°i b·∫±ng Semantic Router
        openai.api_key = os.getenv("OPENAI_API_KEY")
        reflection = Reflection(openai)
        rewritten_query = reflection.rewrite(messages, query)
        route_result = router.guide(rewritten_query)
        best_route = route_result[1]
        print(route_result)
        print(f"[Semantic Router] ‚Üí Ph√¢n lo·∫°i: {best_route}")

        if best_route == "uncertain":
            # C√≥ th·ªÉ h·ªèi l·∫°i user ho·∫∑c fallback sang chitchat
            print("ü§î Em kh√¥ng ch·∫Øc ch·∫Øn c√¢u h·ªèi n√†y. Anh/ch·ªã c√≥ th·ªÉ n√≥i r√µ h∆°n ƒë∆∞·ª£c kh√¥ng?")
            continue

        elif best_route == "products":
            # RAG with Elasticsearch
            results = es_db.search(query)
            for i, result in enumerate(results):
                print(f"üîç K·∫øt qu·∫£ {i + 1}: {result['title']}")
                print(f"   Th√¥ng tin: {result['information'][:100]}...")
            context = "\n".join([doc["information"] for doc in results])


            new_system_content = messages[0]["content"] + f"\nD·ªØ li·ªáu s·∫£n ph·∫©m li√™n quan:\n{context}"
            messages[0]["content"] = new_system_content
            messages.append({"role": "user", "content": query})
        else:
            messages.append({"role": "user", "content": query})

        response = embedding.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages
        )
        reply = response.choices[0].message.content.strip()
        print("ü§ñ Tr·∫£ l·ªùi:", reply)
        print("-" * 80)

        messages.append({"role": "assistant", "content": reply})


    
if __name__ == "__main__":
    main()
